{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import folium\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "url = \"https://127.0.0.1:9200/vic-weather/_search\"\n",
    "\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"size\": 100,\n",
    "    \"query\": {\n",
    "        \"match_all\": {}\n",
    "    },\n",
    "    \"sort\": [\n",
    "        {\n",
    "            \"timestamp\": {\n",
    "                \"order\": \"desc\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "response = requests.get(url, headers=headers, auth=HTTPBasicAuth('elastic', 'elastic'), json=data, verify=False)\n",
    "\n",
    "response_json = response.json()\n",
    "\n",
    "hits = response_json['hits']['hits']\n",
    "\n",
    "latest_records = {}\n",
    "for hit in hits:\n",
    "    source = hit['_source']\n",
    "    coords = (source['geo']['lat'], source['geo']['lon'])\n",
    "    if coords not in latest_records:\n",
    "        latest_records[coords] = source\n",
    "\n",
    "\n",
    "features = []\n",
    "for coords, source in latest_records.items():\n",
    "    feature = {\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": [coords[1], coords[0]]\n",
    "        },\n",
    "        \"properties\": {\n",
    "            \"stationid\": source['stationid'],\n",
    "            \"timestamp\": source['timestamp'],\n",
    "            \"name\": source['name'],\n",
    "            \"air_temp\": source['air_temp'],\n",
    "            \"apparent_t\": source['apparent_t'],\n",
    "            \"rel_hum\": source['rel_hum'],\n",
    "            \"rain_trace\": source['rain_trace'],\n",
    "            \"wind_dir\": source['wind_dir'],\n",
    "            \"wind_spd_kmh\": source['wind_spd_kmh']\n",
    "        }\n",
    "    }\n",
    "    features.append(feature)\n",
    "\n",
    "geojson_data = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": features\n",
    "}\n",
    "\n",
    "m = folium.Map(location=[-37.8, 145.0], zoom_start=8)\n",
    "\n",
    "for feature in geojson_data['features']:\n",
    "    lon, lat = feature['geometry']['coordinates']\n",
    "    popup_content = f\"\"\"\n",
    "    <b>Station:</b> {feature['properties']['name']}<br>\n",
    "    <b>Temperature:</b> {feature['properties']['air_temp']} °C<br>\n",
    "    <b>Apparent Temperature:</b> {feature['properties']['apparent_t']} °C<br>\n",
    "    <b>Humidity:</b> {feature['properties']['rel_hum']}%<br>\n",
    "    <b>Wind Direction:</b> {feature['properties']['wind_dir']}<br>\n",
    "    <b>Wind Speed:</b> {feature['properties']['wind_spd_kmh']} km/h<br>\n",
    "    <b>Timestamp:</b> {feature['properties']['timestamp']}\n",
    "    \"\"\"\n",
    "    folium.Marker(\n",
    "        location=[lat, lon],\n",
    "        popup=folium.Popup(popup_content, max_width=300)\n",
    "    ).add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m.save('weather_map.html')\n",
    "\n",
    "# uncomment the following line if you are running this script in Jupyter Notebook\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import folium\n",
    "\n",
    "# Elasticsearch URL\n",
    "bicycle_url = \"https://127.0.0.1:9200/bicycle_count_2015-/_search\"\n",
    "\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"size\": 1000,\n",
    "    \"query\": {\n",
    "        \"match_all\": {}\n",
    "    }\n",
    "    # ,\n",
    "    # \"sort\": [\n",
    "    #     {\n",
    "    #         \"begin_time\": {\n",
    "    #             \"order\": \"desc\"\n",
    "    #         }\n",
    "    #     }\n",
    "    # ]\n",
    "}\n",
    "\n",
    "\n",
    "bicycle_response = requests.get(bicycle_url, headers=headers, auth=HTTPBasicAuth('elastic', 'elastic'), json=data, verify=False)\n",
    "bicycle_data = bicycle_response.json()\n",
    "\n",
    "# print the json response with formatted\n",
    "print(json.dumps(bicycle_data, indent=2))\n",
    "\n",
    "\n",
    "bicycle_hits = bicycle_data['hits']['hits']\n",
    "bicycle_marker_data = []\n",
    "for hit in bicycle_hits:\n",
    "    source = hit['_source']\n",
    "    lat = source['latitude']\n",
    "    lon = source['longitude']\n",
    "    count = source['count']\n",
    "    description = source['descripti2']\n",
    "    popup_content = f\"\"\"\n",
    "    <b>Count:</b> {count}<br>\n",
    "    <b>Description:</b> {description}<br>\n",
    "    <b>Coordinates:</b> ({lat}, {lon})\n",
    "    \"\"\"\n",
    "    bicycle_marker_data.append({\n",
    "        'lat': lat,\n",
    "        'lon': lon,\n",
    "        'popup_content': popup_content\n",
    "    })\n",
    "\n",
    "\n",
    "m = folium.Map(location=[-37.8136, 144.9631], zoom_start=10)\n",
    "\n",
    "for data in bicycle_marker_data:\n",
    "    folium.Marker(\n",
    "        location=[data['lat'], data['lon']],\n",
    "        popup=folium.Popup(data['popup_content'], max_width=300)\n",
    "    ).add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m.save('bicycle_data_map.html')\n",
    "\n",
    "# uncomment the following line to display the map in Jupyter Notebook\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import numpy as np\n",
    "\n",
    "url = \"https://127.0.0.1:9200/air-qualities/_search\"\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"size\": 1000,\n",
    "    \"query\": {\n",
    "        \"match_all\": {}\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, auth=HTTPBasicAuth('elastic', 'elastic'), json=data, verify=False)\n",
    "\n",
    "response_json = response.json()\n",
    "\n",
    "hits = response_json['hits']['hits']\n",
    "\n",
    "print(json.dumps(hits, indent=2))\n",
    "\n",
    "heat_data = []\n",
    "for hit in hits:\n",
    "    source = hit['_source']\n",
    "    lat = source['geometry']['lat']\n",
    "    lon = source['geometry']['lon']\n",
    "    value = source['averageValue']\n",
    "    timestamp = source['since']\n",
    "    \n",
    "    if isinstance(lat, (int, float)) and isinstance(lon, (int, float)) and isinstance(value, (int, float)):\n",
    "        heat_data.append([lat, lon, value])\n",
    "\n",
    "heat_data = [point for point in heat_data if not any(isinstance(i, (type(None), float)) and (not isinstance(i, bool)) and np.isnan(i) for i in point)]\n",
    "\n",
    "m = folium.Map(location=[-37.8136, 144.9631], zoom_start=6)\n",
    "\n",
    "HeatMap(heat_data, min_opacity=0.5, radius=25, blur=15, gradient={0.2: 'blue', 0.4: 'lime', 0.6: 'yellow', 0.8: 'orange', 1: 'red'}).add_to(m)\n",
    "\n",
    "geojson_path = 'states.geojson'\n",
    "folium.GeoJson(\n",
    "    geojson_path,\n",
    "    name='Australian States',\n",
    "    style_function=lambda feature: {\n",
    "        'color': 'black',\n",
    "        'weight': 2,\n",
    "        'fillOpacity': 0\n",
    "    }\n",
    ").add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m.save('air_quality_heatmap.html')\n",
    "\n",
    "# uncomment the following line to display the map\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "from pytz import UTC\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import folium\n",
    "import math\n",
    "\n",
    "air_quality_url = \"https://127.0.0.1:9200/air-qualities/_search\"\n",
    "weather_url = \"https://127.0.0.1:9200/vic-weather/_search\"\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "query = {\n",
    "    \"size\": 1000,\n",
    "    \"query\": {\n",
    "        \"match_all\": {}\n",
    "    }\n",
    "}\n",
    "\n",
    "response_aq = requests.get(air_quality_url, headers=headers, auth=HTTPBasicAuth('elastic', 'elastic'), json=query, verify=False)\n",
    "air_quality_data = response_aq.json()\n",
    "\n",
    "response_weather = requests.get(weather_url, headers=headers, auth=HTTPBasicAuth('elastic', 'elastic'), json=query, verify=False)\n",
    "weather_data = response_weather.json()\n",
    "\n",
    "air_quality_records = []\n",
    "for hit in air_quality_data['hits']['hits']:\n",
    "    source = hit['_source']\n",
    "    record = {\n",
    "        'siteID': source['siteID'],\n",
    "        'siteName': source['siteName'],\n",
    "        'lat': float(source['geometry']['lat']),\n",
    "        'lon': float(source['geometry']['lon']),\n",
    "        'dataName': source['dataName'],\n",
    "        'averageValue': source['averageValue'],\n",
    "        'unit': source['unit'],\n",
    "        'timestamp': parser.parse(source['since']).astimezone(UTC)\n",
    "    }\n",
    "    air_quality_records.append(record)\n",
    "\n",
    "weather_records = []\n",
    "for hit in weather_data['hits']['hits']:\n",
    "    source = hit['_source']\n",
    "    record = {\n",
    "        'stationid': source['stationid'],\n",
    "        'name': source['name'],\n",
    "        'lat': float(source['geo']['lat']),\n",
    "        'lon': float(source['geo']['lon']),\n",
    "        'air_temp': source['air_temp'],\n",
    "        'apparent_t': source['apparent_t'],\n",
    "        'rel_hum': source['rel_hum'],\n",
    "        'rain_trace': source['rain_trace'],\n",
    "        'wind_dir': source['wind_dir'],\n",
    "        'wind_spd_kmh': source['wind_spd_kmh'],\n",
    "        'timestamp': parser.parse(source['timestamp']).astimezone(UTC)\n",
    "    }\n",
    "    weather_records.append(record)\n",
    "\n",
    "df_air_quality = pd.DataFrame(air_quality_records)\n",
    "df_weather = pd.DataFrame(weather_records)\n",
    "\n",
    "print(df_air_quality.head())\n",
    "print(\"\\n\\n\\n\")\n",
    "print(df_weather.head())\n",
    "\n",
    "df_combined = pd.merge_asof(\n",
    "    df_air_quality.sort_values('timestamp'), \n",
    "    df_weather.sort_values('timestamp'), \n",
    "    on='timestamp', \n",
    "    by=['lat', 'lon'], \n",
    "    direction='nearest', \n",
    "    tolerance=pd.Timedelta('1h')\n",
    ")\n",
    "\n",
    "df_combined.dropna(inplace=True)\n",
    "\n",
    "print(df_combined.head())\n",
    "\n",
    "m = folium.Map(location=[-37.8136, 144.9631], zoom_start=8)\n",
    "\n",
    "def calculate_arrow_end(lat, lon, wind_dir, wind_spd_kmh):\n",
    "    arrow_length = wind_spd_kmh / 100.0\n",
    "\n",
    "    angle_dict = {\n",
    "        'N': 0, 'NNE': 22.5, 'NE': 45, 'ENE': 67.5, 'E': 90, 'ESE': 112.5,\n",
    "        'SE': 135, 'SSE': 157.5, 'S': 180, 'SSW': 202.5, 'SW': 225, 'WSW': 247.5,\n",
    "        'W': 270, 'WNW': 292.5, 'NW': 315, 'NNW': 337.5\n",
    "    }\n",
    "    angle = angle_dict.get(wind_dir, 0)\n",
    "\n",
    "    end_lat = lat + arrow_length * math.cos(math.radians(angle))\n",
    "    end_lon = lon + arrow_length * math.sin(math.radians(angle))\n",
    "\n",
    "    return end_lat, end_lon\n",
    "\n",
    "for index, row in df_weather.iterrows():\n",
    "    lat, lon = row['lat'], row['lon']\n",
    "    wind_dir = row['wind_dir']\n",
    "    wind_spd_kmh = row['wind_spd_kmh']\n",
    "    end_lat, end_lon = calculate_arrow_end(lat, lon, wind_dir, wind_spd_kmh)\n",
    "\n",
    "    folium.PolyLine(\n",
    "        locations=[(lat, lon), (end_lat, end_lon)],\n",
    "        color='blue',\n",
    "        weight=2,\n",
    "        opacity=0.6,\n",
    "        tooltip=f\"Wind: {wind_dir} at {wind_spd_kmh} km/h\"\n",
    "    ).add_to(m)\n",
    "\n",
    "\n",
    "    popup_content = f\"\"\"\n",
    "    <b>Station:</b> {row['name']}<br>\n",
    "    <b>Temperature:</b> {row['air_temp']} °C<br>\n",
    "    <b>Apparent Temperature:</b> {row['apparent_t']} °C<br>\n",
    "    <b>Humidity:</b> {row['rel_hum']}%<br>\n",
    "    <b>Rain:</b> {row['rain_trace']} mm<br>\n",
    "    <b>Wind:</b> {wind_dir} at {wind_spd_kmh} km/h\n",
    "    \"\"\"\n",
    "    folium.Marker(\n",
    "        location=[lat, lon],\n",
    "        popup=folium.Popup(popup_content, max_width=300)\n",
    "    ).add_to(m)\n",
    "\n",
    "\n",
    "m.save('weather_wind_map.html')\n",
    "\n",
    "\n",
    "# uncomment the following line to display the map in Jupyter Notebook\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_twitter_heat_data():\n",
    "    url = \"https://127.0.0.1:9200/geo_twitter_data/_search\"\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    data = {\n",
    "        \"size\": 1000,\n",
    "        \"query\": {\"match_all\": {}},\n",
    "        \"sort\": [{\"created_at\": {\"order\": \"desc\"}}]\n",
    "    }\n",
    "    response = requests.get(url, headers=headers, auth=HTTPBasicAuth('elastic', 'elastic'), json=data, verify=False)\n",
    "    response_json = response.json()\n",
    "    hits = response_json['hits']['hits']\n",
    "    \n",
    "    heat_data = []\n",
    "    for hit in hits:\n",
    "        source = hit['_source']\n",
    "        bbox = source['bbox']['coordinates'][0]\n",
    "        lon = sum([point[0] for point in bbox]) / len(bbox)\n",
    "        lat = sum([point[1] for point in bbox]) / len(bbox)\n",
    "        heat_data.append([lat, lon, source['sentiment']])\n",
    "    \n",
    "    return heat_data\n",
    "\n",
    "\n",
    "def get_air_quality_heat_data():\n",
    "    url = \"https://127.0.0.1:9200/air-qualities/_search\"\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    data = {\"size\": 1000, \"query\": {\"match_all\": {}}}\n",
    "    response = requests.get(url, headers=headers, auth=HTTPBasicAuth('elastic', 'elastic'), json=data, verify=False)\n",
    "    response_json = response.json()\n",
    "    hits = response_json['hits']['hits']\n",
    "    \n",
    "    heat_data = []\n",
    "    for hit in hits:\n",
    "        source = hit['_source']\n",
    "        lat = source['geometry']['lat']\n",
    "        lon = source['geometry']['lon']\n",
    "        value = source['averageValue']\n",
    "        \n",
    "        if isinstance(lat, (int, float)) and isinstance(lon, (int, float)) and isinstance(value, (int, float)):\n",
    "            heat_data.append([lat, lon, value])\n",
    "    \n",
    "    heat_data = [point for point in heat_data if not any(isinstance(i, (type(None), float)) and (not isinstance(i, bool)) and np.isnan(i) for i in point)]\n",
    "    return heat_data\n",
    "\n",
    "\n",
    "def get_vic_weather_heat_data():\n",
    "    url = \"https://127.0.0.1:9200/vic-weather/_search\"\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    data = {\"size\": 1000, \"query\": {\"match_all\": {}}}\n",
    "    response = requests.get(url, headers=headers, auth=HTTPBasicAuth('elastic', 'elastic'), json=data, verify=False)\n",
    "    response_json = response.json()\n",
    "    hits = response_json['hits']['hits']\n",
    "    \n",
    "    heat_data = []\n",
    "    for hit in hits:\n",
    "        source = hit['_source']\n",
    "        lat = source['geo']['lat']\n",
    "        lon = source['geo']['lon']\n",
    "        value = source['air_temp']\n",
    "        \n",
    "        if isinstance(lat, (int, float)) and isinstance(lon, (int, float)) and isinstance(value, (int, float)):\n",
    "            heat_data.append([lat, lon, value])\n",
    "    \n",
    "    heat_data = [point for point in heat_data if not any(isinstance(i, (type(None), float)) and (not isinstance(i, bool)) and np.isnan(i) for i in point)]\n",
    "    return heat_data\n",
    "\n",
    "\n",
    "def get_nsw_weather_heat_data():\n",
    "    url = \"https://127.0.0.1:9200/nsw-weather/_search\"\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    data = {\"size\": 1000, \"query\": {\"match_all\": {}}}\n",
    "    response = requests.get(url, headers=headers, auth=HTTPBasicAuth('elastic', 'elastic'), json=data, verify=False)\n",
    "    response_json = response.json()\n",
    "    hits = response_json['hits']['hits']\n",
    "    \n",
    "    heat_data = []\n",
    "    for hit in hits:\n",
    "        source = hit['_source']\n",
    "        lat = source['geo']['lat']\n",
    "        lon = source['geo']['lon']\n",
    "        value = source['air_temp']\n",
    "        \n",
    "        if isinstance(lat, (int, float)) and isinstance(lon, (int, float)) and isinstance(value, (int, float)):\n",
    "            heat_data.append([lat, lon, value])\n",
    "    \n",
    "    heat_data = [point for point in heat_data if not any(isinstance(i, (type(None), float)) and (not isinstance(i, bool)) and np.isnan(i) for i in point)]\n",
    "    return heat_data\n",
    "\n",
    "\n",
    "twitter_heat_data = get_twitter_heat_data()\n",
    "air_quality_heat_data = get_air_quality_heat_data()\n",
    "vic_weather_heat_data = get_vic_weather_heat_data()\n",
    "nsw_weather_heat_data = get_nsw_weather_heat_data()\n",
    "\n",
    "\n",
    "m = folium.Map(location=[-33.8688, 151.2093], zoom_start=4)\n",
    "\n",
    "\n",
    "twitter_heatmap = folium.FeatureGroup(name='Twitter Sentiment Heatmap')\n",
    "HeatMap(twitter_heat_data, min_opacity=0.5, radius=15, blur=10).add_to(twitter_heatmap)\n",
    "twitter_heatmap.add_to(m)\n",
    "\n",
    "\n",
    "air_quality_heatmap = folium.FeatureGroup(name='Air Quality Heatmap')\n",
    "HeatMap(air_quality_heat_data, min_opacity=0.5, radius=25, blur=15, gradient={0.2: 'blue', 0.4: 'lime', 0.6: 'yellow', 0.8: 'orange', 1: 'red'}).add_to(air_quality_heatmap)\n",
    "air_quality_heatmap.add_to(m)\n",
    "\n",
    "\n",
    "vic_weather_heatmap = folium.FeatureGroup(name='VIC Weather Heatmap')\n",
    "HeatMap(vic_weather_heat_data, min_opacity=0.5, radius=25, blur=15, gradient={0.2: 'blue', 0.4: 'lime', 0.6: 'yellow', 0.8: 'orange', 1: 'red'}).add_to(vic_weather_heatmap)\n",
    "vic_weather_heatmap.add_to(m)\n",
    "\n",
    "\n",
    "nsw_weather_heatmap = folium.FeatureGroup(name='NSW Weather Heatmap')\n",
    "HeatMap(nsw_weather_heat_data, min_opacity=0.5, radius=25, blur=15, gradient={0.2: 'blue', 0.4: 'lime', 0.6: 'yellow', 0.8: 'orange', 1: 'red'}).add_to(nsw_weather_heatmap)\n",
    "nsw_weather_heatmap.add_to(m)\n",
    "\n",
    "\n",
    "geojson_path = 'states.geojson'\n",
    "state_boundaries = folium.FeatureGroup(name='Australian States')\n",
    "folium.GeoJson(\n",
    "    geojson_path,\n",
    "    name='Australian States',\n",
    "    style_function=lambda feature: {\n",
    "        'color': 'black',\n",
    "        'weight': 2,\n",
    "        'fillOpacity': 0\n",
    "    }\n",
    ").add_to(state_boundaries)\n",
    "state_boundaries.add_to(m)\n",
    "\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "\n",
    "m.save('combined_heatmap.html')\n",
    "\n",
    "\n",
    "# uncomment the following line to display the map in Jupyter Notebook\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "url = \"https://127.0.0.1:9200/vic-weather/_search\"\n",
    "\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"size\": 1000,\n",
    "    \"query\": {\n",
    "        \"match_all\": {}\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "response = requests.get(url, headers=headers, auth=HTTPBasicAuth('elastic', 'elastic'), json=data, verify=False)\n",
    "\n",
    "\n",
    "response_json = response.json()\n",
    "\n",
    "\n",
    "hits = response_json['hits']['hits']\n",
    "\n",
    "\n",
    "heat_data = []\n",
    "for hit in hits:\n",
    "    source = hit['_source']\n",
    "    lat = source['geo']['lat']\n",
    "    lon = source['geo']['lon']\n",
    "    value = source['air_temp']\n",
    "    \n",
    "\n",
    "    if isinstance(lat, (int, float)) and isinstance(lon, (int, float)) and isinstance(value, (int, float)):\n",
    "\n",
    "        heat_data.append([lat, lon, value])\n",
    "\n",
    "\n",
    "heat_data = [point for point in heat_data if not any(isinstance(i, (type(None), float)) and (not isinstance(i, bool)) and np.isnan(i) for i in point)]\n",
    "\n",
    "\n",
    "\n",
    "m = folium.Map(location=[-37.8136, 144.9631], zoom_start=6)\n",
    "\n",
    "\n",
    "HeatMap(heat_data, min_opacity=0.5, radius=25, blur=15, gradient={0.2: 'blue', 0.4: 'lime', 0.6: 'yellow', 0.8: 'orange', 1: 'red'}).add_to(m)\n",
    "\n",
    "\n",
    "geojson_path = 'states.geojson'\n",
    "folium.GeoJson(\n",
    "    geojson_path,\n",
    "    name='Australian States',\n",
    "    style_function=lambda feature: {\n",
    "        'color': 'black',\n",
    "        'weight': 2,\n",
    "        'fillOpacity': 0\n",
    "    }\n",
    ").add_to(m)\n",
    "\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "\n",
    "m.save('vic_weather_heatmap.html')\n",
    "\n",
    "# uncomment the following line to display the map in Jupyter Notebook\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "import pytz\n",
    "import folium\n",
    "from folium.plugins import HeatMapWithTime\n",
    "\n",
    "url = \"https://127.0.0.1:9200/vic-weather/_search\"\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"size\": 1000,\n",
    "    \"query\": {\n",
    "        \"match_all\": {}\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, auth=HTTPBasicAuth('elastic', 'elastic'), json=data, verify=False)\n",
    "\n",
    "response_json = response.json()\n",
    "\n",
    "hits = response_json['hits']['hits']\n",
    "\n",
    "weather_records = []\n",
    "for hit in hits:\n",
    "    source = hit['_source']\n",
    "    record = {\n",
    "        'lat': source['geo']['lat'],\n",
    "        'lon': source['geo']['lon'],\n",
    "        'air_temp': source['air_temp'],\n",
    "        'timestamp': parser.parse(source['timestamp']).astimezone(pytz.UTC)\n",
    "    }\n",
    "    weather_records.append(record)\n",
    "\n",
    "df_weather = pd.DataFrame(weather_records)\n",
    "\n",
    "print(df_weather.head())\n",
    "\n",
    "heat_data = []\n",
    "timestamps = []\n",
    "\n",
    "for timestamp, group in df_weather.groupby(pd.Grouper(key='timestamp', freq='1H')):\n",
    "    heat_data.append([[row['lat'], row['lon'], row['air_temp']] for _, row in group.iterrows()])\n",
    "    timestamps.append(timestamp.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "print(heat_data[:2])\n",
    "print(timestamps[:2])\n",
    "\n",
    "m = folium.Map(location=[-37.8136, 144.9631], zoom_start=6)\n",
    "\n",
    "heatmap = HeatMapWithTime(\n",
    "    heat_data,\n",
    "    index=timestamps,\n",
    "    radius=25,\n",
    "    gradient={0.2: 'blue', 0.4: 'lime', 0.6: 'yellow', 0.8: 'orange', 1: 'red'},\n",
    "    auto_play=True,\n",
    "    max_opacity=0.8\n",
    ")\n",
    "\n",
    "heatmap.add_to(m)\n",
    "\n",
    "geojson_path = 'states.geojson'\n",
    "folium.GeoJson(\n",
    "    geojson_path,\n",
    "    name='Australian States',\n",
    "    style_function=lambda feature: {\n",
    "        'color': 'black',\n",
    "        'weight': 2,\n",
    "        'fillOpacity': 0\n",
    "    }\n",
    ").add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m.save('vic_weather_timeslider_heatmap.html')\n",
    "\n",
    "# uncomment the following line to display the map in Jupyter Notebook\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from shapely.geometry import shape\n",
    "import geopandas as gpd\n",
    "\n",
    "url = 'http://localhost:9090/traffic-injury'\n",
    "\n",
    "headers = {\n",
    "    'Accept': 'application/json',\n",
    "    'Content-Type': 'application/json',\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "print(f\"HTTP response status code: {response.status_code}\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    try:\n",
    "        data = response.text\n",
    "\n",
    "        print(f\"HTTP response content: {data[:500]}...\")\n",
    "\n",
    "        data = json.loads(data)\n",
    "\n",
    "        print(json.dumps(data, indent=2))\n",
    "\n",
    "        if 'error' in data:\n",
    "            print(f\"Error from server: {data['error']}\")\n",
    "        else:\n",
    "            suic_df = pd.DataFrame(data['data'])\n",
    "\n",
    "            print(suic_df.columns)\n",
    "\n",
    "            suic_df['geometry'] = suic_df['geometry'].apply(lambda x: shape(x) if x else None)\n",
    "\n",
    "            gdf = gpd.GeoDataFrame(suic_df, geometry='geometry')\n",
    "\n",
    "            geojson_file = 'traffic-injury.geojson'\n",
    "            gdf.to_file(geojson_file, driver='GeoJSON')\n",
    "\n",
    "            print(f\"GeoJSON file saved as {geojson_file}\")\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "        print(f\"Response content: {data[:500]}...\")\n",
    "else:\n",
    "    print(f\"HTTP request failed with status code {response.status_code}\")\n",
    "    print(f\"Error message: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "geojson_file = 'traffic-injury.geojson'\n",
    "gdf = gpd.read_file(geojson_file)\n",
    "\n",
    "m = folium.Map(location=[gdf.geometry.centroid.y.mean(), gdf.geometry.centroid.x.mean()], zoom_start=6)\n",
    "\n",
    "folium.GeoJson(\n",
    "    gdf,\n",
    "    name='Traffic Injuries',\n",
    "    style_function=lambda feature: {\n",
    "        'fillColor': '#blue',\n",
    "        'color': 'black',\n",
    "        'weight': 2,\n",
    "        'fillOpacity': 0.5,\n",
    "    },\n",
    "    tooltip=folium.GeoJsonTooltip(\n",
    "        fields=['phn_name', 'count_traffic_injury', 'ratio_traffic_injury'],\n",
    "        aliases=['Region:', 'Traffic Injuries:', 'Injury Ratio:'],\n",
    "        localize=True\n",
    "    ),\n",
    "    popup=folium.GeoJsonPopup(\n",
    "        fields=['phn_name', 'count_traffic_injury', 'ratio_traffic_injury'],\n",
    "        aliases=['Region:', 'Traffic Injuries:', 'Injury Ratio:'],\n",
    "        localize=True\n",
    "    )\n",
    ").add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m.save('traffic_injury_map.html')\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "def get_vic_weather_data():\n",
    "    url = \"https://127.0.0.1:9200/vic-weather/_search\"\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    data = {\n",
    "        \"size\": 1000,\n",
    "        \"query\": {\"match_all\": {}},\n",
    "        \"sort\": [{\"timestamp\": {\"order\": \"desc\"}}]\n",
    "    }\n",
    "    response = requests.get(url, headers=headers, auth=HTTPBasicAuth('elastic', 'elastic'), json=data, verify=False)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "    response_json = response.json()\n",
    "    hits = response_json.get('hits', {}).get('hits', [])\n",
    "    \n",
    "    weather_data = []\n",
    "    for hit in hits:\n",
    "        source = hit.get('_source', {})\n",
    "        lat = source.get('geo', {}).get('lat')\n",
    "        lon = source.get('geo', {}).get('lon')\n",
    "        rain = source.get('rain_trace')\n",
    "        if rain == '-':\n",
    "            rain = 0.0\n",
    "        else:\n",
    "            try:\n",
    "                rain = float(rain)\n",
    "            except ValueError:\n",
    "                rain = 0.0\n",
    "\n",
    "        if isinstance(lat, (int, float)) and isinstance(lon, (int, float)) and isinstance(rain, (int, float)):\n",
    "            weather_data.append([lat, lon, rain])\n",
    "    \n",
    "    print(\"VIC Weather Data:\", weather_data)\n",
    "    return weather_data\n",
    "\n",
    "def get_nsw_weather_data():\n",
    "    url = \"https://127.0.0.1:9200/nsw-weather/_search\"\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    data = {\n",
    "        \"size\": 1000,\n",
    "        \"query\": {\"match_all\": {}},\n",
    "        \"sort\": [{\"timestamp\": {\"order\": \"desc\"}}]\n",
    "    }\n",
    "    response = requests.get(url, headers=headers, auth=HTTPBasicAuth('elastic', 'elastic'), json=data, verify=False)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "    response_json = response.json()\n",
    "    hits = response_json.get('hits', {}).get('hits', [])\n",
    "    \n",
    "    weather_data = []\n",
    "    for hit in hits:\n",
    "        source = hit.get('_source', {})\n",
    "        lat = source.get('geo', {}).get('lat')\n",
    "        lon = source.get('geo', {}).get('lon')\n",
    "        rain = source.get('rain_trace')\n",
    "        if rain == '-':\n",
    "            rain = 0.0\n",
    "        else:\n",
    "            try:\n",
    "                rain = float(rain)\n",
    "            except ValueError:\n",
    "                rain = 0.0\n",
    "\n",
    "        if isinstance(lat, (int, float)) and isinstance(lon, (int, float)) and isinstance(rain, (int, float)):\n",
    "            weather_data.append([lat, lon, rain])\n",
    "    \n",
    "    print(\"NSW Weather Data:\", weather_data)\n",
    "    return weather_data\n",
    "\n",
    "vic_weather_data = get_vic_weather_data()\n",
    "nsw_weather_data = get_nsw_weather_data()\n",
    "\n",
    "if not vic_weather_data:\n",
    "    print(\"No VIC weather data found.\")\n",
    "if not nsw_weather_data:\n",
    "    print(\"No NSW weather data found.\")\n",
    "\n",
    "traffic_injury_gdf = gpd.read_file('traffic-injury.geojson')\n",
    "\n",
    "print(\"Traffic Injury GDF bounds:\")\n",
    "print(traffic_injury_gdf.total_bounds)\n",
    "\n",
    "def check_overlap(bounds1, bounds2):\n",
    "    return not (bounds1[0] > bounds2[2] or bounds1[2] < bounds2[0] or bounds1[1] > bounds2[3] or bounds1[3] < bounds2[1])\n",
    "\n",
    "if vic_weather_data:\n",
    "    vic_bounds = [min([p[1] for p in vic_weather_data]), min([p[0] for p in vic_weather_data]), max([p[1] for p in vic_weather_data]), max([p[0] for p in vic_weather_data])]\n",
    "    print(\"VIC Weather data overlap:\", check_overlap(traffic_injury_gdf.total_bounds, vic_bounds))\n",
    "\n",
    "if nsw_weather_data:\n",
    "    nsw_bounds = [min([p[1] for p in nsw_weather_data]), min([p[0] for p in nsw_weather_data]), max([p[1] for p in nsw_weather_data]), max([p[0] for p in nsw_weather_data])]\n",
    "    print(\"NSW Weather data overlap:\", check_overlap(traffic_injury_gdf.total_bounds, nsw_bounds))\n",
    "\n",
    "if vic_weather_data:\n",
    "    vic_weather_gdf = gpd.GeoDataFrame(vic_weather_data, columns=['lat', 'lon', 'rain'], geometry=gpd.points_from_xy([p[1] for p in vic_weather_data], [p[0] for p in vic_weather_data]), crs=\"EPSG:4326\")\n",
    "\n",
    "if nsw_weather_data:\n",
    "    nsw_weather_gdf = gpd.GeoDataFrame(nsw_weather_data, columns=['lat', 'lon', 'rain'], geometry=gpd.points_from_xy([p[1] for p in nsw_weather_data], [p[0] for p in nsw_weather_data]), crs=\"EPSG:4326\")\n",
    "\n",
    "if vic_weather_data and vic_weather_gdf.crs != traffic_injury_gdf.crs:\n",
    "    vic_weather_gdf = vic_weather_gdf.to_crs(traffic_injury_gdf.crs)\n",
    "if nsw_weather_data and nsw_weather_gdf.crs != traffic_injury_gdf.crs:\n",
    "    nsw_weather_gdf = nsw_weather_gdf.to_crs(traffic_injury_gdf.crs)\n",
    "\n",
    "if vic_weather_data:\n",
    "    vic_weather_gdf['coords'] = vic_weather_gdf['geometry'].apply(lambda geom: (geom.x, geom.y))\n",
    "    vic_weather_grouped = vic_weather_gdf.groupby('coords').agg({\n",
    "        'rain': 'mean',\n",
    "        'geometry': 'first'\n",
    "    }).reset_index()\n",
    "\n",
    "if nsw_weather_data:\n",
    "    nsw_weather_gdf['coords'] = nsw_weather_gdf['geometry'].apply(lambda geom: (geom.x, geom.y))\n",
    "    nsw_weather_grouped = nsw_weather_gdf.groupby('coords').agg({\n",
    "        'rain': 'mean',\n",
    "        'geometry': 'first'\n",
    "    }).reset_index()\n",
    "\n",
    "print(\"Traffic Injury GDF Geometry Type:\")\n",
    "print(traffic_injury_gdf.geom_type.unique())\n",
    "\n",
    "if vic_weather_data:\n",
    "    print(\"VIC Weather GDF Sample:\")\n",
    "    print(vic_weather_gdf.head())\n",
    "if nsw_weather_data:\n",
    "    print(\"NSW Weather GDF Sample:\")\n",
    "    print(nsw_weather_gdf.head())\n",
    "print(\"Traffic Injury GDF Sample:\")\n",
    "print(traffic_injury_gdf.head())\n",
    "\n",
    "if vic_weather_data:\n",
    "    vic_joined_gdf = gpd.sjoin(vic_weather_gdf, traffic_injury_gdf, how=\"inner\", op='within')\n",
    "if nsw_weather_data:\n",
    "    nsw_joined_gdf = gpd.sjoin(nsw_weather_gdf, traffic_injury_gdf, how=\"inner\", op='within')\n",
    "\n",
    "if vic_weather_data:\n",
    "    print(\"VIC Joined Data:\")\n",
    "    print(vic_joined_gdf.head())\n",
    "if nsw_weather_data:\n",
    "    print(\"NSW Joined Data:\")\n",
    "    print(nsw_joined_gdf.head())\n",
    "\n",
    "if vic_weather_data and 'injury_ratio' in vic_joined_gdf.columns and 'rain' in vic_joined_gdf.columns:\n",
    "    vic_grouped = vic_joined_gdf.groupby('phn_name').agg({\n",
    "        'rain': 'mean',\n",
    "        'injury_ratio': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    print(\"VIC Grouped Data:\")\n",
    "    print(vic_grouped)\n",
    "\n",
    "    traffic_injury_gdf = traffic_injury_gdf.merge(vic_grouped, on='phn_name', suffixes=('_orig', '_vic'))\n",
    "    print(\"Traffic Injury Data with VIC Grouped Values:\")\n",
    "    print(traffic_injury_gdf.head())\n",
    "\n",
    "if nsw_weather_data and 'injury_ratio' in nsw_joined_gdf.columns and 'rain' in nsw_joined_gdf.columns:\n",
    "    nsw_grouped = nsw_joined_gdf.groupby('phn_name').agg({\n",
    "        'rain': 'mean',\n",
    "        'injury_ratio': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    print(\"NSW Grouped Data:\")\n",
    "    print(nsw_grouped)\n",
    "\n",
    "    traffic_injury_gdf = traffic_injury_gdf.merge(nsw_grouped, on='phn_name', suffixes=('_vic', '_nsw'))\n",
    "    print(\"Traffic Injury Data with NSW Grouped Values:\")\n",
    "    print(traffic_injury_gdf.head())\n",
    "\n",
    "m = folium.Map(location=[traffic_injury_gdf.geometry.centroid.y.mean(), traffic_injury_gdf.geometry.centroid.x.mean()], zoom_start=6)\n",
    "\n",
    "folium.Choropleth(\n",
    "    geo_data=traffic_injury_gdf,\n",
    "    name='choropleth',\n",
    "    data=traffic_injury_gdf,\n",
    "    columns=['phn_name', 'ratio_traffic_injury'],\n",
    "    key_on='feature.properties.phn_name',\n",
    "    fill_color='YlGn',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    legend_name='Traffic Injury (ratio_traffic_injury)'\n",
    ").add_to(m)\n",
    "\n",
    "# Custom MarkerCluster to display aggregated rainfall values\n",
    "class CustomMarkerCluster(MarkerCluster):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def add_child(self, child, name=None, index=None):\n",
    "        super().add_child(child, name, index)\n",
    "        # Update cluster popups with rainfall sums\n",
    "        for cluster in self._children.values():\n",
    "            if isinstance(cluster, folium.plugins.marker_cluster.MarkerCluster):\n",
    "                cluster_sum = 0\n",
    "                for marker in cluster._children.values():\n",
    "                    if isinstance(marker, folium.map.Marker):\n",
    "                        try:\n",
    "                            rain_value = float(marker.popup._content.split(': ')[1])\n",
    "                            cluster_sum += rain_value\n",
    "                        except:\n",
    "                            continue\n",
    "                cluster.bindPopup(f'Rainfall Sum: {cluster_sum:.2f}')\n",
    "\n",
    "if vic_weather_data:\n",
    "    marker_cluster = CustomMarkerCluster(name='VIC Rainfall Cluster', disableClusteringAtZoom=8).add_to(m)\n",
    "\n",
    "    for idx, row in vic_weather_grouped.iterrows():\n",
    "        folium.Marker(\n",
    "            location=[row.geometry.y, row.geometry.x],\n",
    "            popup=folium.Popup(f'Rainfall: {row[\"rain\"]:.2f}'),\n",
    "            icon=folium.DivIcon(html=f\"\"\"<div style=\"font-size: 12pt; color : black\">{row[\"rain\"]:.2f}</div>\"\"\")\n",
    "        ).add_to(marker_cluster)\n",
    "\n",
    "if nsw_weather_data:\n",
    "    marker_cluster = CustomMarkerCluster(name='NSW Rainfall Cluster', disableClusteringAtZoom=8).add_to(m)\n",
    "\n",
    "    for idx, row in nsw_weather_grouped.iterrows():\n",
    "        folium.Marker(\n",
    "            location=[row.geometry.y, row.geometry.x],\n",
    "            popup=folium.Popup(f'Rainfall: {row[\"rain\"]:.2f}'),\n",
    "            icon=folium.DivIcon(html=f\"\"\"<div style=\"font-size: 12pt; color : black\">{row[\"rain\"]:.2f}</div>\"\"\")\n",
    "        ).add_to(marker_cluster)\n",
    "\n",
    "geojson_path = 'states.geojson'\n",
    "state_boundaries = folium.FeatureGroup(name='Australian States')\n",
    "folium.GeoJson(\n",
    "    geojson_path,\n",
    "    name='Australian States',\n",
    "    style_function=lambda feature: {\n",
    "        'color': 'black',\n",
    "        'weight': 2,\n",
    "        'fillOpacity': 0\n",
    "    }\n",
    ").add_to(state_boundaries)\n",
    "state_boundaries.add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m.save('traffic_injury_weather_map.html')\n",
    "print(\"Map has been saved as 'traffic_injury_weather_map.html'\")\n",
    "\n",
    "# uncomment the following line to display the map in Jupyter Notebook\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "vic_weather_df = pd.DataFrame(vic_weather_data, columns=['lat', 'lon', 'rain'])\n",
    "nsw_weather_df = pd.DataFrame(nsw_weather_data, columns=['lat', 'lon', 'rain'])\n",
    "\n",
    "vic_weather_df['state'] = 'VIC'\n",
    "nsw_weather_df['state'] = 'NSW'\n",
    "\n",
    "combined_weather_df = pd.concat([vic_weather_df, nsw_weather_df])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='state', y='rain', data=combined_weather_df)\n",
    "plt.title('Box Plot of Rainfall in VIC and NSW')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Rainfall (mm)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "vic_weather_df = pd.DataFrame(vic_weather_data, columns=['lat', 'lon', 'rain'])\n",
    "nsw_weather_df = pd.DataFrame(nsw_weather_data, columns=['lat', 'lon', 'rain'])\n",
    "\n",
    "vic_weather_df['state'] = 'VIC'\n",
    "nsw_weather_df['state'] = 'NSW'\n",
    "\n",
    "combined_weather_df = pd.concat([vic_weather_df, nsw_weather_df])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(data=combined_weather_df, x='rain', hue='state', fill=True, common_norm=False, alpha=0.5)\n",
    "plt.title('Density Plot of Rainfall in VIC and NSW')\n",
    "plt.xlabel('Rainfall (mm)')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traffic_injury_gdf.describe())\n",
    "if vic_weather_data:\n",
    "    print(vic_weather_gdf.describe())\n",
    "if nsw_weather_data:\n",
    "    print(nsw_weather_gdf.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if vic_weather_data:\n",
    "    print(\"VIC Joined Data Columns:\")\n",
    "    print(vic_joined_gdf.columns)\n",
    "\n",
    "if nsw_weather_data:\n",
    "    print(\"NSW Joined Data Columns:\")\n",
    "    print(nsw_joined_gdf.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "from pytz import UTC\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "air_quality_url = \"https://127.0.0.1:9200/air-qualities/_search\"\n",
    "weather_url = \"https://127.0.0.1:9200/nsw-weather/_search\"\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "query = {\n",
    "    \"size\": 1000,\n",
    "    \"query\": {\n",
    "        \"match_all\": {}\n",
    "    }\n",
    "}\n",
    "\n",
    "response_aq = requests.get(air_quality_url, headers=headers, auth=HTTPBasicAuth('elastic', 'elastic'), json=query, verify=False)\n",
    "air_quality_data = response_aq.json()\n",
    "\n",
    "response_weather = requests.get(weather_url, headers=headers, auth=HTTPBasicAuth('elastic', 'elastic'), json=query, verify=False)\n",
    "weather_data = response_weather.json()\n",
    "\n",
    "air_quality_records = []\n",
    "for hit in air_quality_data['hits']['hits']:\n",
    "    source = hit['_source']\n",
    "    record = {\n",
    "        'siteID': source['siteID'],\n",
    "        'siteName': source['siteName'],\n",
    "        'lat': float(source['geometry']['lat']),\n",
    "        'lon': float(source['geometry']['lon']),\n",
    "        'dataName': source['dataName'],\n",
    "        'averageValue': source['averageValue'],\n",
    "        'unit': source['unit'],\n",
    "        'timestamp': parser.parse(source['since']).astimezone(UTC)\n",
    "    }\n",
    "    air_quality_records.append(record)\n",
    "\n",
    "weather_records = []\n",
    "for hit in weather_data['hits']['hits']:\n",
    "    source = hit['_source']\n",
    "    record = {\n",
    "        'stationid': source['stationid'],\n",
    "        'name': source['name'],\n",
    "        'lat': float(source['geo']['lat']),\n",
    "        'lon': float(source['geo']['lon']),\n",
    "        'air_temp': source['air_temp'],\n",
    "        'apparent_t': source['apparent_t'],\n",
    "        'rel_hum': source['rel_hum'],\n",
    "        'rain_trace': source['rain_trace'],\n",
    "        'wind_dir': source['wind_dir'],\n",
    "        'wind_spd_kmh': source['wind_spd_kmh'],\n",
    "        'timestamp': parser.parse(source['timestamp']).astimezone(UTC)\n",
    "    }\n",
    "    weather_records.append(record)\n",
    "\n",
    "\n",
    "df_air_quality = pd.DataFrame(air_quality_records)\n",
    "df_weather = pd.DataFrame(weather_records)\n",
    "\n",
    "\n",
    "print(df_air_quality.head(10))\n",
    "print(\"\\n\\n\\n\")\n",
    "print(df_weather.head(10))\n",
    "\n",
    "\n",
    "df_combined = pd.merge_asof(\n",
    "    df_air_quality.sort_values('timestamp'), \n",
    "    df_weather.sort_values('timestamp'), \n",
    "    on='timestamp', \n",
    "    by=['lat', 'lon'], \n",
    "    direction='nearest', \n",
    "    tolerance=pd.Timedelta('1h')\n",
    ")\n",
    "\n",
    "\n",
    "df_combined.dropna(inplace=True)\n",
    "\n",
    "\n",
    "print(df_combined.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "\n",
    "air_quality_url = \"https://127.0.0.1:9200/air-qualities/_search\"\n",
    "vic_weather_url = \"https://127.0.0.1:9200/vic-weather/_search\"\n",
    "nsw_weather_url = \"https://127.0.0.1:9200/nsw-weather/_search\"\n",
    "\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "\n",
    "query = {\n",
    "    \"size\": 1000,\n",
    "    \"query\": {\n",
    "        \"match_all\": {}\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def get_data(url):\n",
    "    response = requests.get(url, headers=headers, auth=HTTPBasicAuth('elastic', 'elastic'), json=query, verify=False)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "air_quality_data = get_data(air_quality_url)\n",
    "vic_weather_data = get_data(vic_weather_url)\n",
    "nsw_weather_data = get_data(nsw_weather_url)\n",
    "\n",
    "\n",
    "def extract_data(data, lat_key, lon_key, value_key, timestamp_key):\n",
    "    records = []\n",
    "    for hit in data['hits']['hits']:\n",
    "        source = hit['_source']\n",
    "        record = {\n",
    "            'lat': float(source['geo'][lat_key]),\n",
    "            'lon': float(source['geo'][lon_key]),\n",
    "            'value': source[value_key],\n",
    "            'timestamp': parser.parse(source[timestamp_key])\n",
    "        }\n",
    "        records.append(record)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "def extract_aq_data(data, lat_key, lon_key, value_key, timestamp_key):\n",
    "    records = []\n",
    "    for hit in data['hits']['hits']:\n",
    "        source = hit['_source']\n",
    "        record = {\n",
    "            'lat': float(source['geometry'][lat_key]),\n",
    "            'lon': float(source['geometry'][lon_key]),\n",
    "            'value': source[value_key],\n",
    "            'timestamp': parser.parse(source[timestamp_key])\n",
    "        }\n",
    "        records.append(record)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "df_air_quality = extract_aq_data(air_quality_data, 'lat', 'lon', 'averageValue', 'since')\n",
    "df_vic_weather = extract_data(vic_weather_data, 'lat', 'lon', 'air_temp', 'timestamp')\n",
    "df_nsw_weather = extract_data(nsw_weather_data, 'lat', 'lon', 'air_temp', 'timestamp')\n",
    "\n",
    "\n",
    "print(df_air_quality.head())\n",
    "print(df_vic_weather.head())\n",
    "print(df_nsw_weather.head())\n",
    "\n",
    "# sort the dataframes by values\n",
    "df_air_quality = df_air_quality.sort_values('value')\n",
    "df_vic_weather = df_vic_weather.sort_values('value')\n",
    "df_nsw_weather = df_nsw_weather.sort_values('value')\n",
    "\n",
    "# print the sorted dataframes\n",
    "print(df_air_quality.head())\n",
    "print(df_vic_weather.head())\n",
    "print(df_nsw_weather.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import branca.colormap as cm\n",
    "from folium.plugins import TimeSliderChoropleth\n",
    "\n",
    "def prepare_timeslider_data(df, value_name):\n",
    "\n",
    "    features = []\n",
    "    for _, row in df.iterrows():\n",
    "        feature = {\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": {\n",
    "                \"type\": \"Point\",\n",
    "                \"coordinates\": [row['lon'], row['lat']],\n",
    "            },\n",
    "            \"properties\": {\n",
    "                \"time\": row['timestamp'].strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
    "                value_name: row['value']\n",
    "            },\n",
    "        }\n",
    "        features.append(feature)\n",
    "    \n",
    "    return {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": features,\n",
    "    }\n",
    "\n",
    "\n",
    "timeslider_data_aq = prepare_timeslider_data(df_air_quality, 'averageValue')\n",
    "timeslider_data_vic_weather = prepare_timeslider_data(df_vic_weather, 'air_temp')\n",
    "timeslider_data_nsw_weather = prepare_timeslider_data(df_nsw_weather, 'air_temp')\n",
    "\n",
    "\n",
    "all_timeslider_data = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": timeslider_data_aq['features'] + timeslider_data_vic_weather['features'] + timeslider_data_nsw_weather['features']\n",
    "}\n",
    "\n",
    "# print all_timeslider_data with format\n",
    "print(json.dumps(all_timeslider_data, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "url = \"https://127.0.0.1:9200/history_weather/_search\"\n",
    "\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"size\": 1000,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"should\": [\n",
    "                {\"range\": {\"Date\": {\"gte\": \"2023-04-01\", \"lte\": \"2023-04-30\"}}},\n",
    "                {\"range\": {\"Date\": {\"gte\": \"2024-04-01\", \"lte\": \"2024-04-30\"}}}\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "response = requests.get(url, headers=headers, auth=HTTPBasicAuth('elastic', 'elastic'), json=data, verify=False)\n",
    "\n",
    "\n",
    "response_json = response.json()\n",
    "\n",
    "\n",
    "with open('weather_data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(response_json, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "with open('weather_data.json', 'r', encoding='utf-8') as f:\n",
    "    response_json = json.load(f)\n",
    "\n",
    "\n",
    "hits = response_json['hits']['hits']\n",
    "\n",
    "\n",
    "weather_data = []\n",
    "for hit in hits:\n",
    "    source = hit['_source']\n",
    "    weather_data.append({\n",
    "        \"Date\": source[\"Date\"],\n",
    "        \"MinTemp(°C)\": source[\"MinTemp(°C)\"],\n",
    "        \"MaxTemp(°C)\": source[\"MaxTemp(°C)\"]\n",
    "    })\n",
    "\n",
    "\n",
    "df = pd.DataFrame(weather_data)\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# print DataFrame head\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "df_2023 = df.loc['2023-04']\n",
    "df_2024 = df.loc['2024-04']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "\n",
    "plt.plot(df_2023.index, df_2023['MinTemp(°C)'], label='2023.4 Min. Temp(°C)', marker='o')\n",
    "plt.plot(df_2023.index, df_2023['MaxTemp(°C)'], label='2023.4 Max. Temp(°C)', marker='x')\n",
    "\n",
    "\n",
    "plt.plot(df_2024.index, df_2024['MinTemp(°C)'], label='2024.4 Min. Temp(°C)', marker='o')\n",
    "plt.plot(df_2024.index, df_2024['MaxTemp(°C)'], label='2024.4 Max. Temp(°C)', marker='x')\n",
    "\n",
    "\n",
    "plt.title('2023.4 and 2024.4 daily Min. and Max. Temperatures')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Temperature (°C)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "url = \"https://127.0.0.1:9200/history_weather/_search\"\n",
    "\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"size\": 1000,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"should\": [\n",
    "                {\"range\": {\"Date\": {\"gte\": \"2023-04-01\", \"lte\": \"2023-04-30\"}}},\n",
    "                {\"range\": {\"Date\": {\"gte\": \"2024-04-01\", \"lte\": \"2024-04-30\"}}}\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "response = requests.get(url, headers=headers, auth=HTTPBasicAuth('elastic', 'elastic'), json=data, verify=False)\n",
    "\n",
    "\n",
    "response_json = response.json()\n",
    "\n",
    "\n",
    "with open('weather_data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(response_json, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "with open('weather_data.json', 'r', encoding='utf-8') as f:\n",
    "    response_json = json.load(f)\n",
    "\n",
    "\n",
    "hits = response_json['hits']['hits']\n",
    "\n",
    "\n",
    "weather_data = []\n",
    "for hit in hits:\n",
    "    source = hit['_source']\n",
    "    weather_data.append({\n",
    "        \"Date\": source[\"Date\"],\n",
    "        \"MinTemp(°C)\": source[\"MinTemp(°C)\"],\n",
    "        \"MaxTemp(°C)\": source[\"MaxTemp(°C)\"]\n",
    "    })\n",
    "\n",
    "\n",
    "df = pd.DataFrame(weather_data)\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# print DataFrame head\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "df_2023 = df.loc['2023-04']\n",
    "df_2024 = df.loc['2024-04']\n",
    "\n",
    "\n",
    "df_2023['AvgTemp(°C)'] = (df_2023['MinTemp(°C)'] + df_2023['MaxTemp(°C)']) / 2\n",
    "df_2024['AvgTemp(°C)'] = (df_2024['MinTemp(°C)'] + df_2024['MaxTemp(°C)']) / 2\n",
    "\n",
    "\n",
    "df_2023['Day'] = df_2023.index.day\n",
    "df_2024['Day'] = df_2024.index.day\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "\n",
    "plt.plot(df_2023['Day'], df_2023['AvgTemp(°C)'], label='2023.4 Avg. Temp.(°C)', marker='o')\n",
    "\n",
    "\n",
    "plt.plot(df_2024['Day'], df_2024['AvgTemp(°C)'], label='2024.4 Avg. Temp.(°C)', marker='x')\n",
    "\n",
    "\n",
    "plt.title('2023.4 and 2024.4 daily Avg. Temperatures')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Temperatures (°C)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
