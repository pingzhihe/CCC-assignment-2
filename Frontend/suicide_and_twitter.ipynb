{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team 8\n",
    "# Name: Can Wang, Kaisheng Su, Mingtao Yang, Zhihe Ping\n",
    "# Student number:1176867, 1241049, 1527052, 1238760\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from shapely.geometry import shape\n",
    "import geopandas as gpd\n",
    "\n",
    "# Define the URL of the fission function\n",
    "url = 'http://localhost:9090/suicide-data'\n",
    "\n",
    "# Set the same request header\n",
    "headers = {\n",
    "    'Accept': 'application/json',\n",
    "    'Content-Type': 'application/json',\n",
    "}\n",
    "\n",
    "# Send a GET request to retrieve data\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check the response status code\n",
    "print(f\"HTTP response status code: {response.status_code}\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    try:\n",
    "        # Directly read the complete response content\n",
    "        data = response.text\n",
    "\n",
    "        # Print the first 500 characters of the complete response content\n",
    "        print(f\"HTTP response content: {data[:500]}...\")\n",
    "\n",
    "        # Parsing JSON data\n",
    "        data = json.loads(data)\n",
    "\n",
    "        # Print data structure\n",
    "        print(json.dumps(data, indent=2))\n",
    "\n",
    "        # Check for errors\n",
    "        if 'error' in data:\n",
    "            print(f\"Error from server: {data['error']}\")\n",
    "        else:\n",
    "            # Convert data to Pandas DataFrame\n",
    "            suic_df = pd.DataFrame(data['data'])\n",
    "\n",
    "            # Print column names\n",
    "            print(suic_df.columns)\n",
    "\n",
    "            # Convert the geometry column to a shapely object\n",
    "            suic_df['geometry'] = suic_df['geometry'].apply(lambda x: shape(x) if x else None)\n",
    "\n",
    "            # Convert to GeoDataFrame\n",
    "            gdf = gpd.GeoDataFrame(suic_df, geometry='geometry')\n",
    "\n",
    "            # Save as GeoJSON file\n",
    "            geojson_file = 'suic_data.geojson'\n",
    "            gdf.to_file(geojson_file, driver='GeoJSON')\n",
    "\n",
    "            print(f\"GeoJSON file saved as {geojson_file}\")\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "        print(f\"Response content: {data[:500]}...\")  \n",
    "else:\n",
    "    print(f\"HTTP request failed with status code {response.status_code}\")\n",
    "    print(f\"Error message: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'suic_data.geojson'\n",
    "premature_gdf = gpd.read_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = premature_gdf\n",
    "premature_gdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "sns.boxplot(y=gdf['ratio_suic'], ax=ax[0])\n",
    "ax[0].set_title('Boxplot of Suicide Death Count')\n",
    "ax[0].set_ylabel('Suicide Death Count')\n",
    "\n",
    "sns.boxplot(y=gdf['count_suic'], ax=ax[1])\n",
    "ax[1].set_title('Boxplot of Suicide Death Ratio')\n",
    "ax[1].set_ylabel('Suicide Death Ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basic statistical description\n",
    "summary_stats = gdf.describe()\n",
    "\n",
    "# Draw a distribution map\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Draw the distribution of suicide deaths\n",
    "gdf['ratio_suic'].plot(kind='density', ax=ax[0])\n",
    "ax[0].set_title('Suicide Death Count Distribution')\n",
    "ax[0].set_xlabel('Suicide Death Count')\n",
    "ax[0].set_ylabel('Frequency')\n",
    "\n",
    "# Draw the distribution of suicide mortality rates\n",
    "gdf['count_suic'].plot(kind='density', ax=ax[1])\n",
    "ax[1].set_title('Suicide Death Ratio Distribution')\n",
    "ax[1].set_xlabel('Suicide Death Ratio')\n",
    "ax[1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a geographical distribution map\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "gdf.plot(ax=ax, column='ratio_suic', legend=True, cmap='OrRd', legend_kwds={'label': \"Suicide Death Count\"})\n",
    "ax.set_title('Geographical Distribution of Suicide Death Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_for_clustering = gdf[['ratio_suic']].dropna()\n",
    "\n",
    "# Using KMeans clustering algorithm\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(data_for_clustering)\n",
    "gdf['cluster'] = kmeans.labels_\n",
    "\n",
    "# Draw a density map of the distribution of suicide deaths\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "#Draw density maps for each cluster\n",
    "for cluster in gdf['cluster'].unique():\n",
    "    subset = gdf[gdf['cluster'] == cluster]\n",
    "    sns.kdeplot(subset['ratio_suic'], ax=ax, label=f'Cluster {cluster}', fill=True)\n",
    "ax.set_title('Suicide Death Count Density by Cluster')\n",
    "ax.set_xlabel('Suicide Death Count')\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data from two groups\n",
    "cluster_0 = gdf[gdf['cluster'] == 0]\n",
    "cluster_1 = gdf[gdf['cluster'] == 1]\n",
    "\n",
    "# Calculate basic statistical information for each group\n",
    "stats_0 = cluster_0[['ratio_suic']].describe()\n",
    "stats_1 = cluster_1[['ratio_suic']].describe()\n",
    "\n",
    "# Display statistical information\n",
    "print(\"Cluster 0 Statistics:\")\n",
    "print(stats_0)\n",
    "\n",
    "print(\"\\nCluster 1 Statistics:\")\n",
    "print(stats_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium import GeoJson\n",
    "from shapely.geometry import shape\n",
    "import json\n",
    "import geopandas as gpd\n",
    "\n",
    "# Ensure that the geometric objects in the geometry column are correct\n",
    "gdf['geometry'] = gdf['geometry'].apply(shape)\n",
    "gdf = gpd.GeoDataFrame(gdf, geometry='geometry')\n",
    "\n",
    "# Creating Map Objects\n",
    "m = folium.Map(location=[gdf.geometry.centroid.y.mean(), gdf.geometry.centroid.x.mean()], zoom_start=6)\n",
    "\n",
    "# Create GeoJson layer\n",
    "geojson_layer = GeoJson(\n",
    "    gdf.to_json(),  \n",
    "    style_function=lambda x: {\n",
    "        'fillColor': '#3186cc', \n",
    "        'color': 'black',\n",
    "        'weight': 1,\n",
    "        'fillOpacity': 0.6\n",
    "    },\n",
    "    tooltip=folium.GeoJsonTooltip(\n",
    "        fields=['phn_name', 'ratio_suic'],  \n",
    "        aliases=['PHN Name:', 'Deaths by Suicide:'],  \n",
    "        localize=True\n",
    "    )\n",
    ")\n",
    "geojson_layer.add_to(m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save('premature_mortality_map.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from shapely.geometry import shape\n",
    "import geopandas as gpd\n",
    "\n",
    "# Define the URL of the Session function\n",
    "url = 'http://localhost:9090/twitter-data'\n",
    "\n",
    "headers = {\n",
    "    'Accept': 'application/json',\n",
    "    'Content-Type': 'application/json',\n",
    "}\n",
    "\n",
    "# Send a GET request to retrieve data\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check the response status code\n",
    "print(f\"HTTP response status code: {response.status_code}\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    try:\n",
    "        \n",
    "        data = response.text\n",
    "\n",
    "        print(f\"HTTP response content: {data[:500]}...\")\n",
    "\n",
    "      \n",
    "        data = json.loads(data)\n",
    "\n",
    "        print(json.dumps(data, indent=2))\n",
    "\n",
    "        \n",
    "        if 'error' in data:\n",
    "            print(f\"Error from server: {data['error']}\")\n",
    "        else:\n",
    "           \n",
    "            geojson_data = data['data']\n",
    "\n",
    "\n",
    "            gdf = gpd.GeoDataFrame.from_features(geojson_data['features'])\n",
    "\n",
    "\n",
    "            geojson_file = 'twitter-data.geojson'\n",
    "            gdf.to_file(geojson_file, driver='GeoJSON')\n",
    "\n",
    "            print(f\"GeoJSON file saved as {geojson_file}\")\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "        print(f\"Response content: {data[:500]}...\")  # 仅打印前500个字符以防止内容过多\n",
    "else:\n",
    "    print(f\"HTTP request failed with status code {response.status_code}\")\n",
    "    print(f\"Error message: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "file_path = 'twitter-data.geojson'\n",
    "twitter_gdf = gpd.read_file(file_path)\n",
    "\n",
    "\n",
    "print(twitter_gdf.info())\n",
    "print(twitter_gdf.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(twitter_gdf.isnull().sum())\n",
    "\n",
    "# 确保geometry列中的几何对象是正确的\n",
    "twitter_gdf['geometry'] = twitter_gdf['geometry'].apply(lambda x: shape(x) if isinstance(x, dict) else x)\n",
    "twitter_gdf = gpd.GeoDataFrame(twitter_gdf, geometry='geometry')\n",
    "\n",
    "# Extract longitude and latitude data\n",
    "twitter_gdf['longitude'] = twitter_gdf.geometry.x\n",
    "twitter_gdf['latitude'] = twitter_gdf.geometry.y\n",
    "\n",
    "# Convert Timestamp type columns to strings\n",
    "if 'created_at' in twitter_gdf.columns:\n",
    "    twitter_gdf['created_at'] = twitter_gdf['created_at'].astype(str)\n",
    "\n",
    "\n",
    "print(twitter_gdf.info())\n",
    "print(twitter_gdf.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium import GeoJson\n",
    "from shapely.geometry import shape, box, Point\n",
    "import json\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Draw a density map of sentiment distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(twitter_gdf['sentiment'], fill=True)\n",
    "plt.title('Sentiment Density Distribution')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Density')   \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the relationship between geographical location and sentiment\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=twitter_gdf, x='longitude', y='latitude', hue='sentiment', palette='coolwarm')\n",
    "plt.title('Geographical Distribution of Sentiment')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.legend(title='Sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium.plugins import MarkerCluster\n",
    "from sklearn.cluster import DBSCAN\n",
    "m = folium.Map(location=[0, 0], zoom_start=2)\n",
    "\n",
    "\n",
    "marker_cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "\n",
    "for idx, row in twitter_gdf.iterrows():\n",
    "   \n",
    "    lon,lat  = row['geometry'].centroid.coords[0]\n",
    "    \n",
    "    folium.Marker([lat,lon], \n",
    "                  popup=f\"Sentiment Score: {row['sentiment']}\").add_to(marker_cluster)\n",
    "\n",
    "\n",
    "m.save('twitter_data_map.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CRS and convert\n",
    "print(\"Premature Mortality CRS:\", premature_gdf.crs)\n",
    "print(\"Twitter CRS:\", twitter_gdf.crs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import folium\n",
    "\n",
    "# Check and ensure CRS consistency\n",
    "if twitter_gdf.crs != premature_gdf.crs:\n",
    "    twitter_gdf = twitter_gdf.to_crs(premature_gdf.crs)\n",
    "\n",
    "# Aggregating the position of duplicate points\n",
    "twitter_gdf['coords'] = twitter_gdf['geometry'].apply(lambda geom: (geom.x, geom.y))\n",
    "twitter_grouped = twitter_gdf.groupby('coords').agg({\n",
    "    'sentiment': 'sum',\n",
    "    'geometry': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "twitter_grouped['sentiment'] = twitter_grouped['sentiment'].round(2)\n",
    "\n",
    "# Check the geometric type of permature_gdf\n",
    "print(\"Premature GDF Geometry Type:\")\n",
    "print(premature_gdf.geom_type.unique())\n",
    "\n",
    "# Make spatial connections\n",
    "joined_gdf = gpd.sjoin(twitter_gdf, premature_gdf, how=\"inner\", op='within')\n",
    "\n",
    "print(\"Joined Data:\")\n",
    "print(joined_gdf.head())\n",
    "\n",
    "# Ensure that the 'dths_rspr0' and 'sentimentnt' columns exist in joined_gdf\n",
    "if 'dths_rspr0' in joined_gdf.columns and 'sentiment' in joined_gdf.columns:\n",
    "    # Calculate the average sentiment and dths_rspr0 for each region\n",
    "    grouped = joined_gdf.groupby('phn_code').agg({\n",
    "        'sentiment': 'mean',\n",
    "        'dths_rspr0': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    print(\"Grouped Data:\")\n",
    "    print(grouped)\n",
    "\n",
    "    # Merge grouped data back into permature_gdf\n",
    "    premature_gdf = premature_gdf.merge(grouped, on='phn_code')\n",
    "    print(\"Premature Mortality Data with Grouped Values:\")\n",
    "    print(premature_gdf.head())\n",
    "\n",
    "\n",
    "    m = folium.Map(location=[premature_gdf.geometry.centroid.y.mean(), premature_gdf.geometry.centroid.x.mean()], zoom_start=6)\n",
    "\n",
    "\n",
    "    folium.Choropleth(\n",
    "        geo_data=premature_gdf,\n",
    "        name='choropleth',\n",
    "        data=premature_gdf,\n",
    "        columns=['phn_code', 'dths_rspr0_x'],\n",
    "        key_on='feature.properties.phn_code',\n",
    "        fill_color='YlGn',\n",
    "        fill_opacity=0.7,\n",
    "        line_opacity=0.2,\n",
    "        legend_name='Premature Mortality (dths_rspr0)'\n",
    "    ).add_to(m)\n",
    "\n",
    "\n",
    "    for idx, row in twitter_grouped.iterrows():\n",
    "        folium.Marker(\n",
    "            location=[row.geometry.y, row.geometry.x],\n",
    "            popup=f'Sentiment Sum: {row[\"sentiment\"]}',\n",
    "            icon=folium.DivIcon(html=f\"\"\"<div style=\"font-size: 12pt; color : black\">{row[\"sentiment\"]:.2f}</div>\"\"\")\n",
    "        ).add_to(m)\n",
    "\n",
    "    m.save('premature_mortality_twitter_map.html')\n",
    "    print(\"Map has been saved as 'premature_mortality_twitter_map.html'\")\n",
    "else:\n",
    "    print(\"Required columns 'dths_rspr0' and 'sentiment' not found in the joined GeoDataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "\n",
    "twitter_gdf = gpd.read_file('twitter-data.geojson')\n",
    "premature_gdf = gpd.read_file('suic_data.geojson')\n",
    "\n",
    "if twitter_gdf.crs != premature_gdf.crs:\n",
    "    twitter_gdf = twitter_gdf.to_crs(premature_gdf.crs)\n",
    "\n",
    "\n",
    "print(\"Twitter GDF bounds:\")\n",
    "print(twitter_gdf.total_bounds)\n",
    "print(\"Premature GDF bounds:\")\n",
    "print(premature_gdf.total_bounds)\n",
    "\n",
    "\n",
    "twitter_bounds = twitter_gdf.total_bounds\n",
    "premature_bounds = premature_gdf.total_bounds\n",
    "\n",
    "if (twitter_bounds[0] > premature_bounds[2] or twitter_bounds[2] < premature_bounds[0] or\n",
    "        twitter_bounds[1] > premature_bounds[3] or twitter_bounds[3] < premature_bounds[1]):\n",
    "    print(\"Twitter points are outside the bounds of the premature data polygons.\")\n",
    "else:\n",
    "    print(\"Twitter points are within the bounds of the premature data polygons.\")\n",
    "\n",
    "# Aggregating the position of duplicate points\n",
    "twitter_gdf['coords'] = twitter_gdf['geometry'].apply(lambda geom: (geom.x, geom.y))\n",
    "twitter_grouped = twitter_gdf.groupby('coords').agg({\n",
    "    'sentiment': 'sum',\n",
    "    'geometry': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "twitter_grouped['sentiment'] = twitter_grouped['sentiment'].round(2)\n",
    "\n",
    "\n",
    "print(\"Premature GDF Geometry Type:\")\n",
    "print(premature_gdf.geom_type.unique())\n",
    "\n",
    "\n",
    "print(\"Twitter GDF Sample:\")\n",
    "print(twitter_gdf.head())\n",
    "print(\"Premature GDF Sample:\")\n",
    "print(premature_gdf.head())\n",
    "\n",
    "\n",
    "joined_gdf = gpd.sjoin(twitter_gdf, premature_gdf, how=\"inner\", op='within')\n",
    "\n",
    "print(\"Joined Data:\")\n",
    "print(joined_gdf.head())\n",
    "\n",
    "\n",
    "if 'ratio_suic' in joined_gdf.columns and 'sentiment' in joined_gdf.columns:\n",
    "    # 计算每个区域的平均 sentiment 和 dths_rspr0\n",
    "    grouped = joined_gdf.groupby('phn_name').agg({\n",
    "        'sentiment': 'mean',\n",
    "        'ratio_suic': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "\n",
    "    print(\"Grouped Data:\")\n",
    "    print(grouped)\n",
    "\n",
    "\n",
    "    premature_gdf = premature_gdf.merge(grouped, on='phn_name')\n",
    "    print(\"Premature Mortality Data with Grouped Values:\")\n",
    "    print(premature_gdf.head())\n",
    "\n",
    "    m = folium.Map(location=[premature_gdf.geometry.centroid.y.mean(), premature_gdf.geometry.centroid.x.mean()], zoom_start=6)\n",
    "\n",
    "\n",
    "    folium.Choropleth(\n",
    "        geo_data=premature_gdf,\n",
    "        name='choropleth',\n",
    "        data=premature_gdf,\n",
    "        columns=['phn_name', 'ratio_suic_x'],\n",
    "        key_on='feature.properties.phn_name',\n",
    "        fill_color='YlGn',\n",
    "        fill_opacity=0.7,\n",
    "        line_opacity=0.2,\n",
    "        legend_name='Premature Mortality (ratio_suic)'\n",
    "    ).add_to(m)\n",
    "\n",
    "    # Custom MarkerCluster to display aggregated sentiment values\n",
    "    class CustomMarkerCluster(MarkerCluster):\n",
    "        def __init__(self, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "\n",
    "        def add_child(self, child, name=None, index=None):\n",
    "            super().add_child(child, name, index)\n",
    "            # Update cluster popups with sentiment sums\n",
    "            for cluster in self._children.values():\n",
    "                if isinstance(cluster, folium.plugins.marker_cluster.MarkerCluster):\n",
    "                    cluster_sum = 0\n",
    "                    for marker in cluster._children.values():\n",
    "                        if isinstance(marker, folium.map.Marker):\n",
    "                            try:\n",
    "                                sentiment_value = float(marker.popup._content.split(': ')[1])\n",
    "                                cluster_sum += sentiment_value\n",
    "                            except:\n",
    "                                continue\n",
    "                    cluster.bindPopup(f'Sentiment Sum: {cluster_sum:.2f}')\n",
    "    marker_cluster = CustomMarkerCluster(name='Sentiment Cluster', disableClusteringAtZoom=8).add_to(m)\n",
    "\n",
    "\n",
    "    for idx, row in twitter_grouped.iterrows():\n",
    "        folium.Marker(\n",
    "            location=[row.geometry.y, row.geometry.x],\n",
    "            popup=folium.Popup(f'Sentiment: {row[\"sentiment\"]:.2f}'),\n",
    "            icon=folium.DivIcon(html=f\"\"\"<div style=\"font-size: 12pt; color : black\">{row[\"sentiment\"]:.2f}</div>\"\"\")\n",
    "        ).add_to(marker_cluster)\n",
    "\n",
    "\n",
    "    # m.save('premature_mortality_twitter_map.html')\n",
    "    print(\"Map has been saved as 'premature_mortality_twitter_map.html'\")\n",
    "else:\n",
    "    print(\"Required columns 'ratio_suic' and 'sentiment' not found in the joined GeoDataFrame.\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data = premature_gdf[['ratio_suic_x', 'sentiment']]\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x='ratio_suic_x', y='sentiment', data=data)\n",
    "plt.title('Relationship between Suicide Ratio and Sentiment')\n",
    "plt.xlabel('Suicide Ratio (ratio_suic_x)')\n",
    "plt.ylabel('Sentiment')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "correlation = data.corr()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(data[['ratio_suic_x']])\n",
    "y_scaled = scaler.fit_transform(data[['sentiment']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "# Calculate Pearson correlation coefficient\n",
    "pearson_corr, pearson_p_value = pearsonr(data['ratio_suic_x'], data['sentiment'])\n",
    "print(f\"Pearson correlation: {pearson_corr}, p-value: {pearson_p_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
